{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a87baef",
   "metadata": {},
   "source": [
    "* https://www.learnpytorch.io/05_pytorch_going_modular/\n",
    "\n",
    "\n",
    "# 05. Going Modular\n",
    "\n",
    "* https://colab.research.google.com/github/mrdbourke/pytorch-deep-learning/blob/main/going_modular/05_pytorch_going_modular_cell_mode.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1682ea88",
   "metadata": {},
   "source": [
    "## 1. Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7fcbf67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "going_modular/data/pizza_steak_sushi directory exists.\n",
      "Downloading pizza, steak, sushi data...\n",
      "Unzipping pizza, steak, sushi data...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "# Setup path to data folder\n",
    "data_path = Path(\"going_modular/data/\")\n",
    "image_path = data_path / \"pizza_steak_sushi\"\n",
    "\n",
    "# If the image folder doesn't exist, download it and prepare it... \n",
    "if image_path.is_dir():\n",
    "    print(f\"{image_path} directory exists.\")\n",
    "else:\n",
    "    print(f\"Did not find {image_path} directory, creating one...\")\n",
    "    image_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "# Download pizza, steak, sushi data\n",
    "with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
    "    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
    "    print(\"Downloading pizza, steak, sushi data...\")\n",
    "    f.write(request.content)\n",
    "\n",
    "# Unzip pizza, steak, sushi data\n",
    "with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
    "    print(\"Unzipping pizza, steak, sushi data...\") \n",
    "    zip_ref.extractall(image_path)\n",
    "\n",
    "# Remove zip file\n",
    "os.remove(data_path / \"pizza_steak_sushi.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acd7f7b",
   "metadata": {},
   "source": [
    "## 2. Create Datasets and DataLoaders\n",
    "\n",
    "Now we'll turn the image dataset into PyTorch `Dataset`'s and `DataLoader`'s. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f67fd03",
   "metadata": {},
   "source": [
    "* https://ipython.readthedocs.io/en/stable/interactive/magics.html#cell-magics\n",
    "\n",
    "We can save a code cell's content using the Jupiter magic `%% writefile filename`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "100d1f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting going_modular/data_setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/data_setup.py\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "def create_dataloaders(\n",
    "        train_dir: str,\n",
    "        test_dir: str,\n",
    "        transform: transforms.Compose,\n",
    "        batch_size: int,\n",
    "        num_workers: int = NUM_WORKERS\n",
    "):\n",
    "    '''\n",
    "    Creates train and test dataloaders\n",
    "\n",
    "    takes in a training directory and testing directory path and turns them into\n",
    "    Pytorch Datasets and then into PyTorch Dataloaders.\n",
    "\n",
    "    Args:\n",
    "        train_dir: Path to training directory\n",
    "        test_dir: Path to testing directory\n",
    "        transform: torchvision transforms to perform on training and testing data\n",
    "        batch_size: size of each image batch\n",
    "        num_workers: number of subprocesses to use for data loading\n",
    "\n",
    "    Returns:\n",
    "        A tuple of (train_dataloader, test_dataloader, class_names).\n",
    "        Where class_names is a list of the target classes.\n",
    "        Either 'pizza', 'steak', 'sushi'\n",
    "    '''\n",
    "    train_data = datasets.ImageFolder(train_dir, transform=transform)\n",
    "    test_data = datasets.ImageFolder(test_dir, transform=transform)\n",
    "    print(f\"Train data:\\n{train_data}\\nTest data:\\n{test_data}\")\n",
    "    # Get class names as a list\n",
    "    class_names = train_data.classes\n",
    "    # Turn train and test Datasets into DataLoaders\n",
    "    train_dataloader = DataLoader(dataset=train_data, \n",
    "                                batch_size=batch_size, # how many samples per batch?\n",
    "                                num_workers=num_workers, # how many subprocesses to use for data loading? (higher = more)\n",
    "                                shuffle=True,\n",
    "                                pin_memory=True) # put data in pinned memory for faster transfer\n",
    "\n",
    "    test_dataloader = DataLoader(dataset=test_data, \n",
    "                                batch_size=batch_size, \n",
    "                                num_workers=num_workers, \n",
    "                                shuffle=False,\n",
    "                                pin_memory=True) \n",
    "    return train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2815c74d",
   "metadata": {},
   "source": [
    "## 3. Making a model (TinyVGG)\n",
    "\n",
    "We're going to use the same model we used in notebook 04: TinyVGG from the CNN Explainer website.\n",
    "\n",
    "The only change here from notebook 04 is that a docstring has been added using [Google's Style Guide for Python](https://google.github.io/styleguide/pyguide.html#384-classes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34bb3b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting going_modular/model_builder.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/model_builder.py\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class TinyVGG(nn.Module):\n",
    "    \"\"\"\n",
    "    Model architecture copying TinyVGG from: \n",
    "    https://poloclub.github.io/cnn-explainer/\n",
    "\n",
    "    Args:\n",
    "        num_blocks: Number of convolutional layers\n",
    "        input_shape: Number of channels in the input\n",
    "        hidden_units: Number of hidden units\n",
    "        output_shape: Number of channels in the output\n",
    "    \"\"\"\n",
    "    def __init__(self, num_blocks: int, input_shape: int, hidden_units: int, output_shape: int) -> None:\n",
    "        super().__init__()\n",
    "        conv_blocks = []\n",
    "        out_conv_blocks = 64\n",
    "        for _ in range(num_blocks):\n",
    "            conv_blocks.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(in_channels=input_shape,\n",
    "                              out_channels=hidden_units,\n",
    "                              kernel_size=3,\n",
    "                              stride=1,\n",
    "                              padding=1),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Conv2d(in_channels=hidden_units,\n",
    "                              out_channels=hidden_units,\n",
    "                              kernel_size=3,\n",
    "                              stride=1,\n",
    "                              padding=1),\n",
    "                    nn.ReLU(),\n",
    "                    nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "                )\n",
    "            )\n",
    "            input_shape = hidden_units\n",
    "            out_conv_blocks = out_conv_blocks // 2\n",
    "        # Transform list of conv_blocks into a sequence of layers\n",
    "        self.conv_blocks = nn.Sequential(*conv_blocks)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            # It's because each layer of our network compresses and changes the shape of our input data.\n",
    "            nn.Linear(in_features=hidden_units*out_conv_blocks*out_conv_blocks, # we divide by 2 for each conv_blocks\n",
    "                      out_features=output_shape)\n",
    "        )\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.classifier(self.conv_blocks(x)) # <- leverage the benefits of operator fusion\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edd7f94",
   "metadata": {},
   "source": [
    "## 4. Creating `train_test_step` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a183c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing going_modular/engine.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/engine.py\n",
    "from typing import Dict, List\n",
    "from timeit import default_timer as timer\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train_test_step(model: torch.nn.Module, \n",
    "                    train_dataloader: torch.utils.data.DataLoader, \n",
    "                    test_dataloader: torch.utils.data.DataLoader, \n",
    "                    loss_fn: torch.nn.Module, \n",
    "                    optimizer: torch.optim.Optimizer, \n",
    "                    device: torch.device,\n",
    "                    epochs: int = 5) -> Dict[str, List[float]]:\n",
    "    results = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_acc\": []\n",
    "    }\n",
    "    torch.manual_seed(42)\n",
    "    train_start = timer()\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        print(f\"Epoch {epoch}\\n-------\")\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        for batch, (X,y) in enumerate(train_dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            model.train().to(device)\n",
    "            y_pred = model(X)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            train_loss += loss\n",
    "            train_acc += ((torch.eq(torch.argmax(dim=1, input=y_pred), y)).sum().item()/len(y_pred))*100\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch % 400 == 0:\n",
    "                print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
    "        train_loss /= len(train_dataloader)\n",
    "        train_acc /= len(train_dataloader)\n",
    "        test_loss = 0\n",
    "        test_acc = 0\n",
    "        model.eval().to(device)\n",
    "        with torch.inference_mode():\n",
    "            for X, y in test_dataloader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                test_pred = model(X)\n",
    "                test_loss += loss_fn(test_pred, y)\n",
    "                test_acc += ((torch.eq(torch.argmax(dim=1, input=test_pred), y)).sum().item()/len(test_pred))*100\n",
    "            test_loss /= len(test_dataloader)\n",
    "            test_acc /= len(test_dataloader)\n",
    "        results[\"train_loss\"].append(train_loss.item())\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss.item())\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "        print(f\"Train loss: {train_loss:.3f} | Train accuracy: {train_acc:.2f}%\")\n",
    "        print(f\"Test loss: {test_loss:.3f} | Test accuracy: {test_acc:.2f}%\")\n",
    "    train_end = timer()\n",
    "    total_time = train_end - train_start\n",
    "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760f459f",
   "metadata": {},
   "source": [
    "## 5. Creating a function to save the model (script mode)\n",
    "\n",
    "How about we add our `save_model()` function to a script called `utils.py` which is short for \"utilities\".\n",
    "\n",
    "We can do so with the magic line `%%writefile going_modular/utils.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ed0fa98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing going_modular/utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/utils.py\n",
    "\"\"\"\n",
    "Contains various utility functions for PyTorch model training and saving.\n",
    "\"\"\"\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "\n",
    "def save_model(model: torch.nn.Module,\n",
    "               target_dir: str,\n",
    "               model_name: str):\n",
    "    \"\"\"Saves a PyTorch model to a target directory.\n",
    "\n",
    "    Args:\n",
    "    model: A target PyTorch model to save.\n",
    "    target_dir: A directory for saving the model to.\n",
    "    model_name: A filename for the saved model. Should include\n",
    "      either \".pth\" or \".pt\" as the file extension.\n",
    "\n",
    "    Example usage:\n",
    "    save_model(model=model_0,\n",
    "               target_dir=\"models\",\n",
    "               model_name=\"05_going_modular_tingvgg_model.pth\")\n",
    "    \"\"\"\n",
    "    # Create target directory\n",
    "    target_dir_path = Path(target_dir)\n",
    "    target_dir_path.mkdir(parents=True,\n",
    "                        exist_ok=True)\n",
    "\n",
    "    # Create model save path\n",
    "    assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \"model_name should end with '.pt' or '.pth'\"\n",
    "    model_save_path = target_dir_path / model_name\n",
    "\n",
    "    # Save the model state_dict()\n",
    "    print(f\"[INFO] Saving model to: {model_save_path}\")\n",
    "    torch.save(obj=model.state_dict(),\n",
    "             f=model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b672d3",
   "metadata": {},
   "source": [
    "## 6. Train, evaluate and save the model\n",
    "\n",
    "Let's leverage the functions we've got above to train, test and save a model to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd4c4502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting going_modular/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/train.py\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from data_setup import create_dataloaders\n",
    "from engine import train_test_step\n",
    "from model_builder import TinyVGG\n",
    "from utils import save_model\n",
    "\n",
    "# Setup hyperparameters\n",
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 32\n",
    "HIDDEN_UNITS = 10\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Setup directories\n",
    "train_dir = \"data/pizza_steak_sushi/train\"\n",
    "test_dir = \"data/pizza_steak_sushi/test\"\n",
    "\n",
    "# Setup target device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Create transforms\n",
    "data_transform = transforms.Compose([\n",
    "  transforms.Resize((64, 64)),\n",
    "  transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Create DataLoaders with help from data_setup.py\n",
    "train_dataloader, test_dataloader, class_names = create_dataloaders(\n",
    "    train_dir=train_dir,\n",
    "    test_dir=test_dir,\n",
    "    transform=data_transform,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Create model with help from model_builder.py\n",
    "model = TinyVGG(\n",
    "    input_shape=3,\n",
    "    hidden_units=HIDDEN_UNITS,\n",
    "    output_shape=len(class_names),\n",
    "    num_blocks=2\n",
    ").to(device)\n",
    "\n",
    "# Set loss and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=LEARNING_RATE)\n",
    "\n",
    "# Start training with help from engine.py\n",
    "results = train_test_step(model=model,\n",
    "          train_dataloader=train_dataloader,\n",
    "          test_dataloader=test_dataloader,\n",
    "          loss_fn=loss_fn,\n",
    "          optimizer=optimizer,\n",
    "          epochs=NUM_EPOCHS,\n",
    "          device=device)\n",
    "\n",
    "# Save the model with help from utils.py\n",
    "save_model(model=model,\n",
    "          target_dir=\"models\",\n",
    "          model_name=\"05_going_modular_script_mode_tinyvgg_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
