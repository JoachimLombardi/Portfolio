{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a87baef",
   "metadata": {},
   "source": [
    "* https://www.learnpytorch.io/05_pytorch_going_modular/\n",
    "\n",
    "\n",
    "# 05. Going Modular\n",
    "\n",
    "* https://colab.research.google.com/github/mrdbourke/pytorch-deep-learning/blob/main/going_modular/05_pytorch_going_modular_cell_mode.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1682ea88",
   "metadata": {},
   "source": [
    "## 1. Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7fcbf67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting going_modular/going_modular/data_import.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/going_modular/data_import.py\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "def get_data(url, file):\n",
    "    '''\n",
    "    Download and extract data\n",
    "\n",
    "    Args:\n",
    "        url: url to download data from\n",
    "        file: name of zip file\n",
    "    '''\n",
    "    # Setup path to data folder\n",
    "    data_path = Path(\"data/\")\n",
    "    image_path = data_path / file\n",
    "\n",
    "    # If the image folder doesn't exist, download it and prepare it... \n",
    "    if image_path.is_dir():\n",
    "        print(f\"{image_path} directory exists.\")\n",
    "    else:\n",
    "        print(f\"Did not find {image_path} directory, creating one...\")\n",
    "        image_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if not os.path.exists(image_path):\n",
    "        # Download data\n",
    "        with open(f\"{image_path}.zip\", \"wb\") as f:\n",
    "            request = requests.get(url)\n",
    "            print(\"Downloading data from\", url)\n",
    "            f.write(request.content)\n",
    "\n",
    "        # Unzip data\n",
    "        with zipfile.ZipFile(f\"{image_path}.zip\", \"r\") as zip_ref:\n",
    "            print(\"Unzipping data...\") \n",
    "            zip_ref.extractall(image_path)\n",
    "\n",
    "        # Remove zip file\n",
    "        os.remove(f\"{image_path}.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acd7f7b",
   "metadata": {},
   "source": [
    "## 2. Create Datasets and DataLoaders\n",
    "\n",
    "Now we'll turn the image dataset into PyTorch `Dataset`'s and `DataLoader`'s. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f67fd03",
   "metadata": {},
   "source": [
    "* https://ipython.readthedocs.io/en/stable/interactive/magics.html#cell-magics\n",
    "\n",
    "We can save a code cell's content using the Jupiter magic `%% writefile filename`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "100d1f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting going_modular/going_modular/data_setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/going_modular/data_setup.py\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "def create_dataloaders(\n",
    "        train_dir: str,\n",
    "        test_dir: str,\n",
    "        transform: transforms.Compose,\n",
    "        batch_size: int,\n",
    "        num_workers: int\n",
    "):\n",
    "    '''\n",
    "    Creates train and test dataloaders\n",
    "\n",
    "    takes in a training directory and testing directory path and turns them into\n",
    "    Pytorch Datasets and then into PyTorch Dataloaders.\n",
    "\n",
    "    Args:\n",
    "        train_dir: Path to training directory\n",
    "        test_dir: Path to testing directory\n",
    "        transform: torchvision transforms to perform on training and testing data\n",
    "        batch_size: size of each image batch\n",
    "        num_workers: number of subprocesses to use for data loading\n",
    "\n",
    "    Returns:\n",
    "        A tuple of (train_dataloader, test_dataloader, class_names).\n",
    "        Where class_names is a list of the target classes.\n",
    "        Either 'pizza', 'steak', 'sushi'\n",
    "    '''\n",
    "    train_data = datasets.ImageFolder(train_dir, transform=transform)\n",
    "    test_data = datasets.ImageFolder(test_dir, transform=transform)\n",
    "    print(f\"Train data:\\n{train_data}\\nTest data:\\n{test_data}\")\n",
    "    # Get class names as a list\n",
    "    class_names = train_data.classes\n",
    "    # Turn train and test Datasets into DataLoaders\n",
    "    train_dataloader = DataLoader(dataset=train_data, \n",
    "                                batch_size=batch_size, # how many samples per batch?\n",
    "                                num_workers=num_workers, # how many subprocesses to use for data loading? (higher = more)\n",
    "                                shuffle=True,\n",
    "                                pin_memory=True) # put data in pinned memory for faster transfer\n",
    "\n",
    "    test_dataloader = DataLoader(dataset=test_data, \n",
    "                                batch_size=batch_size, \n",
    "                                num_workers=num_workers, \n",
    "                                shuffle=False,\n",
    "                                pin_memory=True) \n",
    "    return train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2815c74d",
   "metadata": {},
   "source": [
    "## 3. Making a model (TinyVGG)\n",
    "\n",
    "We're going to use the same model we used in notebook 04: TinyVGG from the CNN Explainer website.\n",
    "\n",
    "The only change here from notebook 04 is that a docstring has been added using [Google's Style Guide for Python](https://google.github.io/styleguide/pyguide.html#384-classes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34bb3b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting going_modular/going_modular/model_builder.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/going_modular/model_builder.py\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class TinyVGG(nn.Module):\n",
    "    \"\"\"\n",
    "    Model architecture copying TinyVGG from: \n",
    "    https://poloclub.github.io/cnn-explainer/\n",
    "\n",
    "    Args:\n",
    "        num_blocks: Number of convolutional layers\n",
    "        input_shape: Number of channels in the input\n",
    "        hidden_units: Number of hidden units\n",
    "        output_shape: Number of channels in the output\n",
    "    \"\"\"\n",
    "    def __init__(self, num_blocks: int, input_shape: int, hidden_units: int, output_shape: int) -> None:\n",
    "        super().__init__()\n",
    "        conv_blocks = []\n",
    "        out_conv_blocks = 64\n",
    "        for _ in range(num_blocks):\n",
    "            conv_blocks.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(in_channels=input_shape,\n",
    "                              out_channels=hidden_units,\n",
    "                              kernel_size=3,\n",
    "                              stride=1,\n",
    "                              padding=1),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Conv2d(in_channels=hidden_units,\n",
    "                              out_channels=hidden_units,\n",
    "                              kernel_size=3,\n",
    "                              stride=1,\n",
    "                              padding=1),\n",
    "                    nn.ReLU(),\n",
    "                    nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "                )\n",
    "            )\n",
    "            input_shape = hidden_units\n",
    "            out_conv_blocks = out_conv_blocks // 2\n",
    "        # Transform list of conv_blocks into a sequence of layers\n",
    "        self.conv_blocks = nn.Sequential(*conv_blocks)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            # It's because each layer of our network compresses and changes the shape of our input data.\n",
    "            nn.Linear(in_features=hidden_units*out_conv_blocks*out_conv_blocks, # we divide by 2 for each conv_blocks\n",
    "                      out_features=output_shape)\n",
    "        )\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.classifier(self.conv_blocks(x)) # <- leverage the benefits of operator fusion\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edd7f94",
   "metadata": {},
   "source": [
    "## 4. Creating `train_test_step` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a183c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting going_modular/going_modular/engine.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/going_modular/engine.py\n",
    "from typing import Dict, List\n",
    "from timeit import default_timer as timer\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train_test_step(model: torch.nn.Module, \n",
    "                    train_dataloader: torch.utils.data.DataLoader, \n",
    "                    test_dataloader: torch.utils.data.DataLoader, \n",
    "                    loss_fn: torch.nn.Module, \n",
    "                    optimizer: torch.optim.Optimizer, \n",
    "                    device: torch.device,\n",
    "                    epochs: int = 5) -> Dict[str, List[float]]:\n",
    "    \"\"\"\n",
    "    Trains and tests a PyTorch model\n",
    "\n",
    "    Turns a target PyTorch model to training mode and then\n",
    "    runs the forward and backward passes on a training dataset.\n",
    "    It also calculates and returns the loss and accuracy on the test dataset\n",
    "\n",
    "    Args:\n",
    "      model: A PyTorch model to be trained and tested\n",
    "      train_dataloader: A DataLoader instance for the model to be trained on\n",
    "      test_dataloader: A DataLoader instance for the model to be tested on\n",
    "      loss_fn: A PyTorch loss function to minimize\n",
    "      optimizer: A PyTorch optimizer to help minimize the loss function\n",
    "      device: A target device to compute on (e.g. \"cuda\" or \"cpu\")\n",
    "\n",
    "    Returns:\n",
    "      A dictionary of training and testing loss as well as training and\n",
    "      testing accuracy metrics. Each metric has a value in a list for \n",
    "      each epoch.\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_acc\": []\n",
    "    }\n",
    "    torch.manual_seed(42)\n",
    "    train_start = timer()\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        print(f\"Epoch {epoch}\\n-------\")\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        for batch, (X,y) in enumerate(train_dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            model.train().to(device)\n",
    "            y_pred = model(X)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            train_loss += loss\n",
    "            train_acc += ((torch.eq(torch.argmax(dim=1, input=y_pred), y)).sum().item()/len(y_pred))*100\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch % 400 == 0:\n",
    "                print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
    "        train_loss /= len(train_dataloader)\n",
    "        train_acc /= len(train_dataloader)\n",
    "        test_loss = 0\n",
    "        test_acc = 0\n",
    "        model.eval().to(device)\n",
    "        with torch.inference_mode():\n",
    "            for X, y in test_dataloader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                test_pred = model(X)\n",
    "                test_loss += loss_fn(test_pred, y)\n",
    "                test_acc += ((torch.eq(torch.argmax(dim=1, input=test_pred), y)).sum().item()/len(test_pred))*100\n",
    "            test_loss /= len(test_dataloader)\n",
    "            test_acc /= len(test_dataloader)\n",
    "        results[\"train_loss\"].append(train_loss.item())\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss.item())\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "        print(f\"Train loss: {train_loss:.3f} | Train accuracy: {train_acc:.2f}%\")\n",
    "        print(f\"Test loss: {test_loss:.3f} | Test accuracy: {test_acc:.2f}%\")\n",
    "    train_end = timer()\n",
    "    total_time = train_end - train_start\n",
    "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760f459f",
   "metadata": {},
   "source": [
    "## 5. Creating a function to save the model (script mode)\n",
    "\n",
    "How about we add our `save_model()` function to a script called `utils.py` which is short for \"utilities\".\n",
    "\n",
    "We can do so with the magic line `%%writefile going_modular/utils.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ed0fa98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting going_modular/going_modular/utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/going_modular/utils.py\n",
    "\"\"\"\n",
    "Contains various utility functions for PyTorch model training and saving.\n",
    "\"\"\"\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "def save_model(model: torch.nn.Module,\n",
    "               target_dir: str,\n",
    "               model_name: str):\n",
    "    \"\"\"Saves a PyTorch model to a target directory.\n",
    "\n",
    "    Args:\n",
    "    model: A target PyTorch model to save.\n",
    "    target_dir: A directory for saving the model to.\n",
    "    model_name: A filename for the saved model. Should include\n",
    "      either \".pth\" or \".pt\" as the file extension.\n",
    "\n",
    "    Example usage:\n",
    "    save_model(model=model_0,\n",
    "               target_dir=\"models\",\n",
    "               model_name=\"05_going_modular_tingvgg_model.pth\")\n",
    "    \"\"\"\n",
    "    # Create target directory\n",
    "    target_dir_path = Path(target_dir)\n",
    "    target_dir_path.mkdir(parents=True,\n",
    "                        exist_ok=True)\n",
    "\n",
    "    # Create model save path\n",
    "    assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \"model_name should end with '.pt' or '.pth'\"\n",
    "    model_save_path = target_dir_path / model_name\n",
    "\n",
    "    # Save the model state_dict()\n",
    "    print(f\"[INFO] Saving model to: {model_save_path}\")\n",
    "    torch.save(obj=model.state_dict(),\n",
    "             f=model_save_path)\n",
    "\n",
    "\n",
    "def load_model(model_path: str,\n",
    "               model_builder: torch.nn.Module,\n",
    "               device: torch.device,\n",
    "               input_shape: int,\n",
    "               output_shape: int,\n",
    "               hidden_units: int,\n",
    "               num_blocks: int):\n",
    "    \n",
    "    '''\n",
    "    Loads a PyTorch model from a target directory.\n",
    "\n",
    "    Args:\n",
    "    model_path: A directory for saving the model to.\n",
    "    model_builder: A model builder to use to create the model.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "    input_shape: Number of channels in the input\n",
    "    output_shape: Number of channels in the output\n",
    "    hidden_units: Number of hidden units\n",
    "    num_blocks: Number of convolutional layers\n",
    "\n",
    "    Returns:\n",
    "    A PyTorch model from a target directory\n",
    "    '''\n",
    "    loaded_model = model_builder(input_shape=input_shape,\n",
    "                                 hidden_units=hidden_units,\n",
    "                                 output_shape=output_shape,\n",
    "                                 num_blocks=num_blocks\n",
    "                                ).to(device)\n",
    "    loaded_model.load_state_dict(torch.load(model_path))\n",
    "    return loaded_model\n",
    "\n",
    "\n",
    "def get_classes(image_dir):\n",
    "\n",
    "  train_path = Path(image_dir)\n",
    "  class_names = [d.name for d in train_path.iterdir() if d.is_dir()]\n",
    "  return class_names\n",
    "\n",
    "\n",
    "def plot_loss_curves(results: Dict[str, List[float]]):\n",
    "    \"\"\"Plots training curves of a results dictionary.\n",
    "\n",
    "    Args:\n",
    "        results (dict): dictionary containing list of values, e.g.\n",
    "            {\"train_loss\": [...],\n",
    "             \"train_acc\": [...],\n",
    "             \"test_loss\": [...],\n",
    "             \"test_acc\": [...]}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the loss values of the results dictionary (training and test)\n",
    "    loss = results['train_loss']\n",
    "    test_loss = results['test_loss']\n",
    "\n",
    "    # Get the accuracy values of the results dictionary (training and test)\n",
    "    accuracy = results['train_acc']\n",
    "    test_accuracy = results['test_acc']\n",
    "\n",
    "    # Figure out how many epochs there were\n",
    "    epochs = range(len(results['train_loss']))\n",
    "\n",
    "    # Setup a plot \n",
    "    plt.figure(figsize=(15, 7))\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, loss, label='train_loss')\n",
    "    plt.plot(epochs, test_loss, label='test_loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, accuracy, label='train_accuracy')\n",
    "    plt.plot(epochs, test_accuracy, label='test_accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b672d3",
   "metadata": {},
   "source": [
    "## 6. Train, evaluate and save the model\n",
    "\n",
    "Let's leverage the functions we've got above to train, test and save a model to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd4c4502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting going_modular/going_modular/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/going_modular/train.py\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from data_import import get_data\n",
    "from data_setup import create_dataloaders\n",
    "from engine import train_test_step\n",
    "from model_builder import TinyVGG\n",
    "from utils import save_model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "   # Setup hyperparameters\n",
    "  NUM_EPOCHS = 5\n",
    "  NUM_BLOCKS = 2\n",
    "  INPUT_SHAPE = 3\n",
    "  BATCH_SIZE = 32\n",
    "  HIDDEN_UNITS = 10\n",
    "  LEARNING_RATE = 0.001\n",
    "  NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "\n",
    "  # Setup target device\n",
    "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "  # Get data\n",
    "  get_data(url=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n",
    "          file=\"pizza_steak_sushi\")\n",
    "\n",
    "  # Setup directories\n",
    "  train_dir = \"data/pizza_steak_sushi/train\"\n",
    "  test_dir = \"data/pizza_steak_sushi/test\"\n",
    "\n",
    "\n",
    "  # Create transforms\n",
    "  data_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  # Create DataLoaders with help from data_setup.py\n",
    "  train_dataloader, test_dataloader, class_names = create_dataloaders(\n",
    "      train_dir=train_dir,\n",
    "      test_dir=test_dir,\n",
    "      transform=data_transform,\n",
    "      batch_size=BATCH_SIZE,\n",
    "      num_workers=NUM_WORKERS\n",
    "  )\n",
    "\n",
    "  # Create model with help from model_builder.py\n",
    "  model = TinyVGG(\n",
    "      input_shape=INPUT_SHAPE,\n",
    "      hidden_units=HIDDEN_UNITS,\n",
    "      output_shape=len(class_names),\n",
    "      num_blocks=NUM_BLOCKS\n",
    "  ).to(device)\n",
    "\n",
    "  # Set loss and optimizer\n",
    "  loss_fn = nn.CrossEntropyLoss()\n",
    "  optimizer = torch.optim.Adam(model.parameters(),\n",
    "                              lr=LEARNING_RATE)\n",
    "\n",
    "  # Start training with help from engine.py\n",
    "  results = train_test_step(model=model,\n",
    "            train_dataloader=train_dataloader,\n",
    "            test_dataloader=test_dataloader,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer,\n",
    "            epochs=NUM_EPOCHS,\n",
    "            device=device)\n",
    "\n",
    "  # Save the model with help from utils.py\n",
    "  save_model(model=model,\n",
    "            target_dir=\"models\",\n",
    "            model_name=\"05_going_modular_script_mode_tinyvgg_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35877192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting going_modular/going_modular/predict.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/going_modular/predict.py\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "def predict_image(img_path, model, class_names, device, image_transform):\n",
    "    '''\n",
    "    Predict the class of a single image.\n",
    "\n",
    "    Args:\n",
    "    img_path: A string path to an image file.\n",
    "    model: A trained PyTorch model.\n",
    "    class_names: A list of class names.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "    image_transform: A transform to apply to the image.\n",
    "    '''\n",
    "\n",
    "    img = Image.open(img_path)\n",
    "    img_transformed = image_transform(img).to(device)\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        pred_logit = model(img_transformed.unsqueeze(0).to(device))\n",
    "        pred_probs = torch.softmax(pred_logit, dim=1)[0]\n",
    "        pred_classes = pred_logit.argmax(1)\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Prediction: {class_names[pred_classes]} | Probability: {pred_probs[pred_classes].item()*100:.2f} %\")\n",
    "    print(f\"Prediction: {class_names[pred_classes]} | Probability: {pred_probs[pred_classes].item()*100:.2f} %\")\n",
    "    plt.axis(\"off\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5302570d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting going_modular/going_modular/test.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/going_modular/test.py\n",
    "from torchvision import transforms\n",
    "from utils import load_model, get_classes\n",
    "from model_builder import TinyVGG\n",
    "from predict import predict_image\n",
    "import torch\n",
    "\n",
    "HIDDEN_UNITS = 10\n",
    "NUM_BLOCKS = 2\n",
    "INPUT_SHAPE = 3\n",
    "\n",
    "# Setup device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# get classes\n",
    "class_names = get_classes(image_dir=\"data/pizza_steak_sushi/train\")\n",
    "\n",
    "# Setup transforms\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load model\n",
    "model = load_model(model_path=\"models/05_going_modular_script_mode_tinyvgg_model.pth\",\n",
    "                   model_builder=TinyVGG,\n",
    "                   device=device,\n",
    "                   input_shape=INPUT_SHAPE,\n",
    "                   output_shape=len(class_names),\n",
    "                   hidden_units=HIDDEN_UNITS,\n",
    "                   num_blocks=NUM_BLOCKS)\n",
    "\n",
    "# Predict\n",
    "predict_image(img_path=\"images/istockphoto-540233806-612x612.jpg\",\n",
    "              model=model,\n",
    "              class_names=class_names,\n",
    "              device=device,\n",
    "              image_transform=image_transform)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
